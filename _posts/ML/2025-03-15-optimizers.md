---
layout: post
title:  "Optimizers"
date:   2025-03-15 05:00:00 +0700
categories: [ml, dl, optimizers]
---

* Adam
* RMSProp
* SGD (Stochastic Gradient Descent)
* Momentum SGD
* Adagrad (Adaptive Gradient)
* Adadelta
* AdamW (Adam with Weight Decay)
* 

